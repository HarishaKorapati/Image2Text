{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding=utf-8 -*-\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/ISE_Final')\n",
        "\n",
        "from gen_train_captions import EOS_TOKEN, SOS_TOKEN\n",
        "from train import get_train_captions, max_length\n",
        "from model import ImgCapModel\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--dataset_root', type=str, required=True, help='/content/drive/MyDrive/ISE_Final/flickr8k')\n",
        "    parser.add_argument('--img_root', type=str, required=True, help='/content/drive/MyDrive/ISE_Final/flickr8k/Flicker8k_Dataset')\n",
        "    parser.add_argument('--model_path', type=str, required=True, help='Path to model.h5')\n",
        "    return parser.parse_args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "\n",
        "    with open(os.path.join(args.dataset_root, 'test_image_feats.pkl'), 'rb') as f:\n",
        "        test_img_feats = joblib.load(f)\n",
        "    test_imgs = list(test_img_feats.keys())\n",
        "    target_img = np.random.choice(test_imgs, 1)[0]\n",
        "    target_img_feat = test_img_feats[target_img].reshape(1, 2048)\n",
        "\n",
        "    with open(os.path.join(args.dataset_root, 'word2idx.pkl'), 'rb') as f:\n",
        "        word2idx = joblib.load(f)\n",
        "    with open(os.path.join(args.dataset_root, 'idx2word.pkl'), 'rb') as f:\n",
        "        idx2word = joblib.load(f)\n",
        "\n",
        "    # Load trained model\n",
        "    img_cap_model = ImgCapModel(vocab_size=len(word2idx.keys()) + 1)\n",
        "    img_cap_model.model.load_weights(args.model_path)\n",
        "    greedy_text = img_cap_model.greedy_search(target_img_feat, word2idx, idx2word)\n",
        "    beam_text = img_cap_model.beam_search(target_img_feat, word2idx, idx2word, beam_width=3)\n",
        "\n",
        "    if args.dataset_root == 'COCO':\n",
        "        target_img = 'COCO_val2014_' + '%012d.jpg' % (target_img)\n",
        "    x = plt.imread(os.path.join(args.img_root, target_img))\n",
        "    plt.imshow(x)\n",
        "    plt.title('\\n'.join(['Greedy: ' + greedy_text, 'Beam:' + beam_text]))\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "mykmttKHlO1k",
        "outputId": "f4862418-64cd-41c3-ca02-0f13c0074a31"
      },
      "id": "mykmttKHlO1k",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] --dataset_root DATASET_ROOT --img_root\n",
            "                             IMG_ROOT --model_path MODEL_PATH\n",
            "ipykernel_launcher.py: error: the following arguments are required: --dataset_root, --img_root, --model_path\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrwDI1jHldVB",
        "outputId": "beb8a3c9-121e-403e-af6e-06e7987ed87c"
      },
      "id": "ZrwDI1jHldVB",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmaQl4T4mnid",
        "outputId": "0c24f536-af8f-4973-e373-6a47de60463b"
      },
      "id": "lmaQl4T4mnid",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding=utf-8 -*-\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/ISE_Final')\n",
        "\n",
        "from gen_train_captions import EOS_TOKEN, SOS_TOKEN\n",
        "from train import get_train_captions, max_length\n",
        "from model import ImgCapModel\n",
        "\n",
        "class Args:\n",
        "    dataset_root = '/content/drive/MyDrive/ISE_Final/flickr8k'\n",
        "    img_root = '/content/drive/MyDrive/ISE_Final/flickr8k/Flicker8k_Dataset'\n",
        "    model_path = 'path_to_your_model/model.h5'  # replace with your model path\n",
        "\n",
        "args = Args()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    with open(os.path.join(args.dataset_root, 'test_image_feats.pkl'), 'rb') as f:\n",
        "        test_img_feats = joblib.load(f)\n",
        "    test_imgs = list(test_img_feats.keys())\n",
        "    target_img = np.random.choice(test_imgs, 1)[0]\n",
        "    target_img_feat = test_img_feats[target_img].reshape(1, 2048)\n",
        "\n",
        "    with open(os.path.join(args.dataset_root, 'word2idx.pkl'), 'rb') as f:\n",
        "        word2idx = joblib.load(f)\n",
        "    with open(os.path.join(args.dataset_root, 'idx2word.pkl'), 'rb') as f:\n",
        "        idx2word = joblib.load(f)\n",
        "\n",
        "    # Load trained model\n",
        "    img_cap_model = ImgCapModel(vocab_size=len(word2idx.keys()) + 1)\n",
        "    img_cap_model.model.load_weights(args.model_path)\n",
        "    greedy_text = img_cap_model.greedy_search(target_img_feat, word2idx, idx2word)\n",
        "    beam_text = img_cap_model.beam_search(target_img_feat, word2idx, idx2word, beam_width=3)\n",
        "\n",
        "    if args.dataset_root == 'COCO':\n",
        "        target_img = 'COCO_val2014_' + '%012d.jpg' % (target_img)\n",
        "    x = plt.imread(os.path.join(args.img_root, target_img))\n",
        "    plt.imshow(x)\n",
        "    plt.title('\\n'.join(['Greedy: ' + greedy_text, 'Beam:' + beam_text]))\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "1RrxbPEWpBeo"
      },
      "id": "1RrxbPEWpBeo",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}